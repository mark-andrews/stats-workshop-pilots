---
title: "Stats 1 R Workshop Pilot: Part 2"
author: |
  | Mark Andrews, Lucy Justics
  | Psychology Department, Nottingham Trent University
  |   
  | \faEnvelopeO\  ```mark.andrews@ntu.ac.uk```
  | \faEnvelopeO\  ```lucy.justice@ntu.ac.uk```
fontsize: 10pt
output:
 beamer_presentation:
  keep_tex: true
  fonttheme: "serif"
  includes:
   in_header: slides_preamble.tex
---


```{r, echo=FALSE}
knitr::opts_chunk$set(echo = TRUE, 
                      prompt = TRUE, warning = FALSE, message = FALSE, comment='#>')

# Thanks to 
# https://github.com/ramnathv/slidify/issues/189#issuecomment-15850008
hook1 <- function(x){ gsub("```\n*```r*\n*", "", x) }
hook2 <- function(x){ gsub("```\n+```\n", "", x) }
knitr::knit_hooks$set(document = hook1)

```


# Set up

* Workshop 2 begins where Workhop 1 ended.

* To set up your R session to continue what we were doing, you need to load some packages and re-import the `data01.csv` file.

* You can load the `tidyverse` package by clicking the tick box before the package name in the *Packages* window, or use the `library` command.
```{r}
library("tidyverse")
```

* The easiest way to import data is using the *Import Dataset* button in the Environment window.

* Use the *From Text (readr)...* option. This uses the `read_csv` R command, which we can run ourselves on the command line.

```{r}
data01 <- read_csv("data01.csv")
```



# Summarizing data with `summarize`

* The `summarize` (or `summarise`) command is a flexible way of getting summary statistics.
```{r}
summarize(data01,
          average_iq = mean(iq),
          average_score = mean(test_score),
          iq_stdev = sd(iq),
          n = n()
)
```


# Summarizing data `by_group`

* We can group the data frame into subsets based on the value of `sex` and then summarize.
```{r}
summarize(group_by(data01, sex),
          average_iq = mean(iq),
          average_score = mean(test_score),
          iq_stdev = sd(iq),
          n = n()
)
```

# Plots and data visualiztion

* The best way to data visualization in R is with `ggplot2`.
* This is loaded when we load the `tidyverse`.
* `ggplot2` is package whose main function is `ggplot`.
* But for relatively simple plots, we can use `qplot`.

# Scatterplot

```{r, out.width='0.75\\textwidth',out.extra='keepaspectratio', fig.align='center'}
qplot(iq, test_score, data=data01)
```

# Scatterplot with `sex` indicated by colour

```{r, out.width='0.75\\textwidth',out.extra='keepaspectratio', fig.align='center'}
qplot(iq, test_score, col=sex, data=data01)
```


# Scatterplot with line of best fit

```{r, out.width='0.75\\textwidth',out.extra='keepaspectratio', fig.align='center'}
qplot(iq, test_score, data=data01) + 
  stat_smooth(method = 'lm')
```


# Scatterplot with line of best fit, for each value of `sex`

```{r, out.width='0.75\\textwidth',out.extra='keepaspectratio', fig.align='center'}
qplot(iq, test_score, col=sex, data=data01) + 
  stat_smooth(method = 'lm')
```

# Changing style of a plot

```{r, out.width='0.75\\textwidth',out.extra='keepaspectratio', fig.align='center'}
qplot(iq, test_score, col=sex, data=data01) +
  stat_smooth(method = 'lm', se=F) +
  theme_classic() +
  xlab('IQ') +
  ylab('Test score')
```


# Independent samples t-test

* Is there a significant difference between males and females on the average value of `test_score`?
```{r}
t.test(test_score ~ sex, data=data01)
```


# Linear regression

* Predict `test_score` as a linear function of `iq` in the `data01` data frame.
```{r}
M <- lm(test_score ~ iq, data=data01)
summary(M)
```

<!-- # Predictions in linear regression -->

<!-- * On the basis of our fitted model ```M```, we can make predictions about possible values of the predictor variable.  -->
<!-- ```{r} -->
<!-- hypothetical_data <- data.frame(education = c(1, 2, 5, 10, 15)) -->
<!-- predict(M, newdata=hypothetical_data) -->
<!-- ``` -->


<!-- # Multiple linear regression -->

<!-- * We can add as many predictor variables as we like. -->
<!-- ```{r} -->
<!-- M <- lm(ACT ~ education + age + gender, data=sat_act) -->
<!-- summary(M) -->
<!-- ``` -->

<!-- # Collinearity -->

<!-- * We'll evaluate multicollinerity using Variance Inflation Factor (VIF): -->
<!-- ```{r} -->
<!-- library(car) -->
<!-- vif(M) -->
<!-- ``` -->

<!-- # General linear models -->

<!-- * We can use predictors that categorical as well as continuous in our model.  -->
<!-- * Here, we investigate how the post treatment weight of a patient differs from their pre treatment weight, for three different types of therapy (control, CBT, family therapy). -->

<!-- ```{r} -->
<!-- anorexia <- read_csv('data/anorexia.csv') -->
<!-- ``` -->

<!-- # General linear models (continued) -->

<!-- * First, we'll visualize the data. -->
<!-- ```{r, out.width='0.75\\textwidth',out.extra='keepaspectratio', fig.align='center'} -->
<!-- ggplot(anorexia, -->
<!--        aes(x = Prewt, y = Postwt, col=Treat)) + -->
<!--   geom_point() + -->
<!--   stat_smooth(method='lm', se=F) + -->
<!--   theme_classic() -->
<!-- ``` -->

<!-- # General linear models (continued) -->

<!-- * Here, we do a *varying intercept*, which is also known as an *ANCOVA*: -->
<!-- ```{r} -->
<!-- M <- lm(Postwt ~ Prewt + Treat, data=anorexia) -->
<!-- summary(M) -->
<!-- ``` -->

<!-- # General linear models (continued) -->

<!-- * We cam also do a *varying slopes and varying intercepts* model. This is a type of interaction model: -->
<!-- ```{r} -->
<!-- M_interaction <- lm(Postwt ~ Prewt * Treat, data=anorexia) -->
<!-- summary(M_interaction) -->
<!-- ``` -->

<!-- # Model evaluation -->

<!-- * We can compare any two linear models using the generic ```anova``` function.  -->
<!-- * Here, we'll use this to test whether the varying slopes and intercepts model is a better fit to the data than the just varying intercepts model: -->

<!-- ```{r} -->
<!-- anova(M, M_interaction) -->
<!-- ``` -->

<!-- # One-way Anova -->

<!-- * We can use `aov` for one-way (and other) Anova. -->
<!-- ```{r} -->
<!-- data(PlantGrowth) -->
<!-- M <- aov(weight ~ group, data=PlantGrowth) -->
<!-- summary(M) -->
<!-- ``` -->

<!-- # Multiple comparisons -->

<!-- * We can do Tukey's range test to perform multiple comparisons: -->
<!-- ```{r} -->
<!-- TukeyHSD(M) -->
<!-- ``` -->

<!-- # One-way Anova (alternative) -->

<!-- * Note that we can also we can do Anova using `lm()`: -->
<!-- ```{r} -->
<!-- M <- lm(weight ~ group, data=PlantGrowth) -->
<!-- anova(M) -->
<!-- ``` -->


<!-- # Two-way anova -->

<!-- ```{r, out.width='0.75\\textwidth',out.extra='keepaspectratio', fig.align='center'} -->
<!-- data("ToothGrowth") -->

<!-- ggplot(ToothGrowth, -->
<!--        aes(x = factor(dose), y = len, col = supp)) + -->
<!--   geom_boxplot() + -->
<!--   theme_classic() -->
<!-- ``` -->


<!-- # Two-way (factorial) anova -->

<!-- ```{r} -->
<!-- M <- aov(len ~ supp*dose, data=ToothGrowth) -->
<!-- summary(M) -->
<!-- ``` -->

<!-- # One-way repeated measures Anova -->

<!-- ```{r} -->
<!-- recall_data <- read_csv('data/recall_data.csv') -->

<!-- M <- aov(Recall ~ Valence + Error(Subject/Valence), data=recall_data) -->
<!-- summary(M) -->
<!-- ``` -->

<!-- # One-way repeated measures Anova (continued) -->

<!-- * Multiple comparisons, with Bonferroni correction -->
<!-- ```{r} -->
<!-- with(recall_data,  -->
<!--      pairwise.t.test(x=Recall, g=Valence),  -->
<!--      p.adjust.methods='bonferroni',  -->
<!--      paired=T) -->
<!-- ``` -->

<!-- # Twoway repeated measures Anova -->
<!-- ```{r} -->
<!-- recall_data2 <- read_csv('data/recall_data2.csv') -->
<!-- M <- aov(Recall ~ Valence*Task + Error(Subject/(Task*Valence)),  -->
<!--          data=recall_data2) -->
<!-- summary(M) -->
<!-- ``` -->


<!-- # Multilevel models -->

<!-- * The repeated measures anova above can be done, and I think *should* be done, using multilevel models too. -->

<!-- ```{r} -->
<!-- library(lme4) -->
<!-- M <- lmer(Recall ~ Valence*Task + (1|Subject), -->
<!--           data=recall_data2) -->
<!-- ``` -->



